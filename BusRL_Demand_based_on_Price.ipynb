{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BusRL_Demand_based_on_Price.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConSeanway/BusinessGameRL/blob/master/BusRL_Demand_based_on_Price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG62GtrNGQ-Z",
        "colab_type": "code",
        "outputId": "ec0ed495-a7ab-487b-ccad-ee64d57f037d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install stable-baselines[mpi]==2.10.0\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting stable-baselines[mpi]==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/fe/db8159d4d79109c6c8942abe77c7ba6b6e008c32ae55870a35e73fa10db3/stable_baselines-2.10.0-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.18.4)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.15.1)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->stable-baselines[mpi]==2.10.0) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Installing collected packages: stable-baselines\n",
            "  Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aDScAS9rZVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "from math import exp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines.common.policies import MlpPolicy\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines import PPO2\n",
        "from stable_baselines import TRPO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81NKbgXSJPRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Sean Conway and Yanzhe Ma\n",
        "Business Game Reinforcement Learning PyProject\n",
        "Updated 28MAY2020\n",
        "'''\n",
        "\n",
        "MAX_PERIODS = 2\n",
        "INITIAL_ASSETS = 100000\n",
        "agentNames = ['Rackhouse LLC', 'Phantom Thieves', 'Team Rocket', 'The Liberal Artists', 'The Consultants']\n",
        "cityNames = ['Atlanta', 'Shanghai', 'Vancouver', 'Tokyo', 'Bethlehem']\n",
        "\n",
        "# Environment is akin to a \"world\" class\n",
        "class Environment():\n",
        "  def __init__(self):\n",
        "    self.period = 1\n",
        "  \n",
        "  def timeskip(self):\n",
        "    self.period += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBfo_dNOFXCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leaderboard class enables us to track which teams are winning the game, and are in which position\n",
        "class Leaderboard():\n",
        "  def __init__(self):\n",
        "    self.leaderboard = {}\n",
        "    for team in agentNames:\n",
        "      self.leaderboard[team] = INITIAL_ASSETS\n",
        "  \n",
        "  # Prints out the leaderboard\n",
        "  def displayLeaderboard(self):\n",
        "    print()\n",
        "    print(\"Current Leaderboard\")\n",
        "    currLeaderboard = sorted(self.leaderboard.items(), reverse=True, key=lambda x: x[1])\n",
        "    for elem in currLeaderboard:\n",
        "        print(elem[0], \" :: $\", elem[1])\n",
        "    print()\n",
        "\n",
        "  # update the leaderboard based upon the values provided\n",
        "  def updateLeaderboard(self, agentList):\n",
        "    newLeaderboard = {}\n",
        "    for team in agentList:\n",
        "      newLeaderboard[team.teamName] = team.totalAssets\n",
        "    self.leaderboard = newLeaderboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KFuBgpEfTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agent class defines a player of the business game (or a team)\n",
        "class Agent():\n",
        "  def __init__(self, teamName):\n",
        "    self.cityPrices = {}\n",
        "    for i in cityNames:  self.cityPrices[i] = 0\n",
        "    self.teamName = teamName\n",
        "    self.totalAssets = INITIAL_ASSETS\n",
        "\n",
        "  # Set price in a given city\n",
        "  def setPriceInCity(self, newPrice, city):\n",
        "    self.cityPrices[city] = newPrice\n",
        "\n",
        "  # Set prices in all cities\n",
        "  def setPrices(self):\n",
        "    # Creating the price list for this period\n",
        "    for city in self.cityPrices.keys():\n",
        "      newPrice = 10\n",
        "      self.setPriceInCity(newPrice, city)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju6iKjMwEa_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Market's purpose is to gather the demand for every agent, and create the demand\n",
        "class Market():\n",
        "  def __init__(self, cityName):\n",
        "    self.teamPrices = {}\n",
        "    for agent in agentNames: self.teamPrices[agent] = 0\n",
        "    self.cityName = cityName\n",
        "    self.totalDemand = 0\n",
        "\n",
        "  # Updates the price for a given team\n",
        "  def updateTeamPrice(self, team, newPrice):\n",
        "    self.teamPrices[team] = newPrice\n",
        "\n",
        "  # Determine the demand for this market, first determining the mean and stdev, and using that to generate a normally distributed demand\n",
        "  def computeDemand(self, period):\n",
        "    meanDemand = self.computeMeanDemand(period)\n",
        "    stdDev = meanDemand / 8\n",
        "    demand = np.random.normal(loc=meanDemand, scale=stdDev)\n",
        "    self.totalDemand = demand\n",
        "    self.printDemand()\n",
        "\n",
        "  # Determine the mean demand for this city, given the period and minimum price\n",
        "  def computeMeanDemand(self, period):\n",
        "    meanDemand = ((1.03) ** period) * 10840 * exp(-0.2216 * min(self.teamPrices.values()) / 10)\n",
        "    return meanDemand\n",
        "\n",
        "  def printDemand(self):\n",
        "    print(str(self.cityName) + \": \" + str(int(self.totalDemand)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH2ZP7kYGdlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialization method for the business game\n",
        "def initializeBusinessGame():\n",
        "\n",
        "  # Initialize the environment, as well as a leaderboard\n",
        "  myEnv = Environment()\n",
        "  myLeaderboard = Leaderboard()\n",
        "\n",
        "  # Create a list of all of the different markets and cities\n",
        "  cityList = []\n",
        "  for i in cityNames: cityList.append(Market(i))\n",
        "\n",
        "  # Create a list of all of the different agents (players) to be used for this game\n",
        "  agentList = []\n",
        "  for i in agentNames: agentList.append(Agent(i))\n",
        "\n",
        "  return myEnv, myLeaderboard, cityList, agentList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU-qPQNHHCFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeAllCityDemands(cityList, agentList):\n",
        "  # Once all agents have set their prices, we're going to compute the demands for each city\n",
        "  for city in cityList:\n",
        "\n",
        "    # Find all prices for the city, then use the minimum to compute demand\n",
        "    for agent in agentList:\n",
        "      city.updateTeamPrice(agent.teamName, agent.cityPrices[city.cityName])\n",
        "\n",
        "    # Determine the mean demand for this period\n",
        "    city.computeDemand(myEnv.period)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LV_4SyPQyzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeMarketShare():\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quCSRYmrHSXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "84eedaaf-9ab6-4732-fedb-820af5a0c996"
      },
      "source": [
        "# Main method of the business game, as abstracted as possible\n",
        "def main():\n",
        "\n",
        "  myEnv, myLeaderboard, cityList, agentList = initializeBusinessGame()\n",
        "\n",
        "  # Run the business game code until the maximum number of periods have been reached\n",
        "  for period in range(MAX_PERIODS):\n",
        "\n",
        "    # Print the header for this period\n",
        "    print(\"Period \" + str(myEnv.period))\n",
        "    print(\"-------------------\")\n",
        "\n",
        "    # Have each agent set prices, decide production quantities, etc. for each period\n",
        "    for agent in agentList:\n",
        "      agent.setPrices()\n",
        "\n",
        "    # Once all agents have set prices, compute city demands, and then compute profits\n",
        "    computeAllCityDemands(cityList, agentList)\n",
        "\n",
        "    # TODO (Work on me please), also write a computeProfit method\n",
        "    computeMarketShare()\n",
        "\n",
        "    # Increment the period, update the leaderboard, and display it\n",
        "    myEnv.timeskip()\n",
        "\n",
        "    myLeaderboard.updateLeaderboard(agentList)\n",
        "    myLeaderboard.displayLeaderboard()\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Period 1\n",
            "-------------------\n",
            "Atlanta: 8731\n",
            "Shanghai: 9114\n",
            "Toronto: 9977\n",
            "Shibuya: 8879\n",
            "\n",
            "Current Leaderboard\n",
            "Rackhouse LLC  :: $ 9000\n",
            "Phantom Thieves  :: $ 9000\n",
            "Team Rocket  :: $ 9000\n",
            "The Liberal Artists  :: $ 9000\n",
            "The Consultants  :: $ 9000\n",
            "\n",
            "Period 2\n",
            "-------------------\n",
            "Atlanta: 9525\n",
            "Shanghai: 11298\n",
            "Toronto: 9358\n",
            "Shibuya: 10111\n",
            "\n",
            "Current Leaderboard\n",
            "Rackhouse LLC  :: $ 9000\n",
            "Phantom Thieves  :: $ 9000\n",
            "Team Rocket  :: $ 9000\n",
            "The Liberal Artists  :: $ 9000\n",
            "The Consultants  :: $ 9000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV95RLaKGhbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomEnv(gym.Env):\n",
        "\n",
        "  def __init__(self, INIT_BALANCE=0, discRate=0.02, maxPeriods=12):\n",
        "    super(CustomEnv, self).__init__()\n",
        "\n",
        "    # Define action and observation space\n",
        "    # They must be gym.spaces objects\n",
        "    # Example when using discrete actions:\n",
        "    self.action_space = spaces.Box(low=np.array([0]), high=np.array([100]),shape = (1,),dtype=np.float32) # Only one action allowed:  change the price for the current period\n",
        "    # observation space: look 3 periods before the current period\n",
        "    self.observation_space = spaces.Box(low=0, high=10, shape=(1,), dtype=np.float32)\n",
        "    \n",
        "    #self.balance = INIT_BALANCE\n",
        "    #self.discountRate = discRate\n",
        "    self.maxPeriods = 1\n",
        "    #self.INIT_BALANCE = INIT_BALANCE\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "    # Rewards will need to be a function\n",
        "    # Multiply the price times the quantity to get the reward (profit)\n",
        "\n",
        "\n",
        "  # DATA STORAGE (columns):\n",
        "  # 0 = time\n",
        "  # 1 = current Price\n",
        "  # 2 = current period reward\n",
        "  # 3 = total reward\n",
        "  # 4 = previous period price\n",
        "  # 5 = previous period reward\n",
        "\n",
        "  def step(self, action):\n",
        "    self.time +=1\n",
        "    price = np.random.normal(self.time*2+20, 2, 1)\n",
        "    reward = -(price-action)**2\n",
        "    self.state = np.array([self.time])\n",
        " \n",
        "    return self.state,reward,self.time > 4,{}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}